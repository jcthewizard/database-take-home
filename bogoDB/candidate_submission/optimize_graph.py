#!/usr/bin/env python3
import json
import os
import sys
from collections import Counter
from typing import Dict, List, Tuple, Any

# Add project root to path to import scripts
script_dir = os.path.dirname(os.path.abspath(__file__))
project_dir = os.path.dirname(script_dir)
sys.path.append(project_dir)

# Import constants
from scripts.constants import (
    NUM_NODES,
    MAX_EDGES_PER_NODE,
    MAX_TOTAL_EDGES,
)

# Architecture constants
INNER_RING_SIZE = 10    # nodes 0-9 get queried the most
MEDIUM_RING_SIZE = 50   # nodes 10-49 get some queries

# Weight constants for predictable path guidance
PRIMARY_WEIGHT = 10.0   # highest priority paths
SECONDARY_WEIGHT = 8.0  # medium priority paths
BACKUP_WEIGHT = 1.0     # low priority backup routes
MEDIUM_RING_LOOPBACK_WEIGHT = 9.0  # weight for node 49 -> 0


def load_graph(graph_file):
    """Load graph from a JSON file.

    Args:
        graph_file: Path to the JSON file containing the graph

    Returns:
        Dict representation of the graph

    Raises:
        FileNotFoundError: If the graph file doesn't exist
        json.JSONDecodeError: If the file contains invalid JSON
    """
    try:
        with open(graph_file, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"ERROR: Graph file not found: {graph_file}")
        raise
    except json.JSONDecodeError as e:
        print(f"ERROR: Invalid JSON in graph file: {e}")
        raise


def load_results(results_file):
    """Load query results from a JSON file.

    Args:
        results_file: Path to the JSON file containing query results

    Returns:
        Dict representation of the query results

    Raises:
        FileNotFoundError: If the results file doesn't exist
        json.JSONDecodeError: If the file contains invalid JSON
    """
    try:
        with open(results_file, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"ERROR: Results file not found: {results_file}")
        raise
    except json.JSONDecodeError as e:
        print(f"ERROR: Invalid JSON in results file: {e}")
        raise


def save_graph(graph, output_file):
    """Save graph to a JSON file.

    Args:
        graph: Graph to save
        output_file: Path where the graph should be saved

    Raises:
        OSError: If the file cannot be written
    """
    try:
        with open(output_file, "w") as f:
            json.dump(graph, f, indent=2)
    except OSError as e:
        print(f"ERROR: Could not save graph to {output_file}: {e}")
        raise


def verify_constraints(graph, max_edges_per_node, max_total_edges):
    """Verify that the graph meets all constraints.

    Args:
        graph: Graph to verify
        max_edges_per_node: Maximum edges allowed per node
        max_total_edges: Maximum total edges allowed

    Returns:
        bool: True if all constraints are met, False otherwise
    """
    # Check total edges
    total_edges = sum(len(edges) for edges in graph.values())
    if total_edges > max_total_edges:
        print(
            f"WARNING: Graph has {total_edges} edges, exceeding limit of {max_total_edges}"
        )
        return False

    # Check max edges per node
    max_node_edges = max(len(edges) for edges in graph.values())
    if max_node_edges > max_edges_per_node:
        print(
            f"WARNING: A node has {max_node_edges} edges, exceeding limit of {max_edges_per_node}"
        )
        return False

    # Check all nodes are present
    if len(graph) != NUM_NODES:
        print(f"WARNING: Graph has {len(graph)} nodes, should have {NUM_NODES}")
        return False

    # Check edge weights are valid (between 0 and 10)
    for node, edges in graph.items():
        for target, weight in edges.items():
            if weight <= 0 or weight > 10:
                print(f"WARNING: Edge {node} -> {target} has invalid weight {weight}")
                return False

    return True


def analyze_query_patterns(results):
    """Analyze query patterns to identify optimization opportunities.

    Args:
        results: Query results data

    Returns:
        Tuple of (target_frequencies, high_value_targets, max_queried_node)
    """
    print("Analyzing query patterns...")

    # Extract query targets and their frequencies
    query_targets = [r["target"] for r in results["detailed_results"]]
    target_frequencies = Counter(query_targets)

    # Sort targets by frequency (most queried first)
    sorted_targets = sorted(target_frequencies.items(), key=lambda x: x[1], reverse=True)

    print(f"Query analysis:")
    print(f"  Total queries: {len(query_targets)}")
    print(f"  Unique targets: {len(target_frequencies)}")
    print(f"  Top 5 most queried: {sorted_targets[:5]}")

    # Identify high-value targets (queried multiple times)
    high_value_targets = [target for target, freq in sorted_targets if freq >= 2]
    print(f"  High-value targets (queried â‰¥2 times): {len(high_value_targets)}")

    # Find the highest queried node to determine our ring size
    max_queried_node = max(query_targets)
    print(f"  Highest queried node: {max_queried_node}")

    return target_frequencies, high_value_targets, max_queried_node


def optimize_graph(
    initial_graph,
    results,
    num_nodes=NUM_NODES,
    max_total_edges=int(MAX_TOTAL_EDGES),
    max_edges_per_node=MAX_EDGES_PER_NODE,
):
    """
    Optimize the graph using ring architecture for optimal random walk performance.

    This function implements a three-tier architecture:
    1. Inner ring (nodes 0-9): Linear progression with maximum weights
    2. Medium ring (nodes 10-49): Three-edge strategy with skip connections
    3. Direct redirection (nodes 50+): All unused nodes point to node 0

    Args:
        initial_graph: Initial graph adjacency list (unused in current implementation)
        results: Results from queries on the initial graph
        num_nodes: Number of nodes in the graph
        max_total_edges: Maximum total edges allowed
        max_edges_per_node: Maximum edges per node

    Returns:
        Optimized graph with ring architecture
    """
    print("Starting graph optimization with ring architecture...")

    # Start fresh - build a new optimized structure
    optimized_graph = {str(i): {} for i in range(num_nodes)}

    # Analyze query patterns to determine ring sizes
    target_frequencies, high_value_targets, max_queried_node = analyze_query_patterns(results)

    print(f"Building inner ring for nodes 0-{INNER_RING_SIZE-1}...")
    print(f"Building medium ring for nodes {INNER_RING_SIZE}-{MEDIUM_RING_SIZE-1}...")
    print(f"Redirecting unused nodes {MEDIUM_RING_SIZE}-{num_nodes-1} to node 0...")

    # Inner ring: simple chain from 0->1->2...->9->10 with maximum weights
    for node_index in range(INNER_RING_SIZE):
        node_str = str(node_index)

        if node_index < INNER_RING_SIZE - 1:
            # Connect to next node (0->1, 1->2, etc.)
            next_node = str(node_index + 1)
            optimized_graph[node_str][next_node] = PRIMARY_WEIGHT
        else:
            # node 9 connects to medium ring start
            optimized_graph[node_str][str(INNER_RING_SIZE)] = SECONDARY_WEIGHT

    # Medium ring: three-edge strategy per node
    for node_index in range(INNER_RING_SIZE, MEDIUM_RING_SIZE):
        node_str = str(node_index)
        edges_added = 0

        # Primary path: go to next node
        if node_index < MEDIUM_RING_SIZE - 1:
            next_node = str(node_index + 1)
            optimized_graph[node_str][next_node] = PRIMARY_WEIGHT
        else:
            # node 49 loops back to start (node 0 is most common target)
            optimized_graph[node_str]["0"] = MEDIUM_RING_LOOPBACK_WEIGHT
        edges_added += 1

        # Add a skip connection for faster traversal
        if edges_added < max_edges_per_node:
            skip_distance = 3  # jump +3 nodes ahead for faster traversal
            skip_target = INNER_RING_SIZE + ((node_index - INNER_RING_SIZE + skip_distance) % (MEDIUM_RING_SIZE - INNER_RING_SIZE))
            if skip_target != node_index:  # don't connect to self
                optimized_graph[node_str][str(skip_target)] = SECONDARY_WEIGHT
                edges_added += 1

        # Low-weight connection back to node 0 as backup
        if edges_added < max_edges_per_node:
            optimized_graph[node_str]["0"] = BACKUP_WEIGHT
            edges_added += 1

    # Nodes 50+ are never queried, so just send them straight to node 0
    print("Redirecting unused nodes to most frequent target...")

    # Simple: all unused nodes point directly to node 0
    for node_index in range(MEDIUM_RING_SIZE, num_nodes):
        node_str = str(node_index)
        optimized_graph[node_str]["0"] = PRIMARY_WEIGHT

    print(f"Added {num_nodes - MEDIUM_RING_SIZE} redirects from unused nodes to node 0")

    # Validate final graph
    final_edges = sum(len(edges) for edges in optimized_graph.values())
    print(f"Optimization complete!")
    print(f"Final edge count: {final_edges} (limit: {max_total_edges})")
    print(f"Edge budget utilization: {final_edges/max_total_edges*100:.1f}%")
    print(f"Configuration: Ring architecture optimized for path length")

    # Make sure we didn't break any rules
    if not verify_constraints(optimized_graph, max_edges_per_node, max_total_edges):
        print("WARNING: Graph doesn't meet constraints!")
        print("The evaluation script will reject it. Need to fix this.")

    return optimized_graph


if __name__ == "__main__":
    # Get file paths
    initial_graph_file = os.path.join(project_dir, "data", "initial_graph.json")
    results_file = os.path.join(project_dir, "data", "initial_results.json")
    output_file = os.path.join(
        project_dir, "candidate_submission", "optimized_graph.json"
    )

    # Create output directory if it doesn't exist
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    try:
        print(f"Loading initial graph from {initial_graph_file}")
        initial_graph = load_graph(initial_graph_file)

        print(f"Loading query results from {results_file}")
        results = load_results(results_file)

        print("Optimizing graph...")
        optimized_graph = optimize_graph(initial_graph, results)

        print(f"Saving optimized graph to {output_file}")
        save_graph(optimized_graph, output_file)

        print("Done! Optimized graph has been saved.")

    except Exception as e:
        print(f"ERROR: Optimization failed: {e}")
        sys.exit(1)
